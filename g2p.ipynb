{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "g2p.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPX9ibCQ3UjiKDmGKjseJZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coryskeers/dl_phones/blob/master/g2p.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVa56WFUUUsU",
        "colab_type": "code",
        "outputId": "23dd783c-843e-46d3-d77f-d8af5b99feba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Download updated CMU ARPABET dictionaries and definitions if they aren't available:\n",
        "import os.path\n",
        "\n",
        "if not os.path.exists('cmudict-0.7b.symbols'):\n",
        "  !wget http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b.symbols\n",
        "#!wget http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b.phones\n",
        "if not os.path.exists('cmudict-0.7b'):\n",
        "  !wget http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b\n",
        "\n",
        "# Build our phoneme descriptions\n",
        "# Based on 'Poetic Sound Similarity Vectors Using Phonetic Features' which uses X-SAMPA phoneme descriptions\n",
        "# Allison Parrish; 2017\n",
        "# https://aaai.org/ocs/index.php/AIIDE/AIIDE17/paper/download/15879/15227\n",
        "phone_defs = {\n",
        "    'AA' : ['bck', 'low', 'unr', 'vwl'],\n",
        "    'AE' : ['fnt', 'low', 'unr', 'vwl'],\n",
        "    'AH' : ['cnt', 'mid', 'unr', 'vwl'],\n",
        "    'AO' : ['bck', 'lmd', 'rnd', 'vwl'],\n",
        "    'AW' : ['bck', 'cnt', 'low', 'rnd', 'smh', 'unr', 'vwl'],\n",
        "    'AY' : ['cnt', 'fnt', 'low', 'smh', 'unr', 'vwl'],\n",
        "    'B' : ['blb', 'stp', 'vcd'],\n",
        "    'CH' : ['alv', 'frc', 'stp', 'vls'],\n",
        "    'D' : ['alv', 'stp', 'vcd'],\n",
        "    'DH' : ['dnt', 'frc', 'vcd'],\n",
        "    'EH' : ['fnt', 'lmd', 'unr', 'vwl'],\n",
        "    'ER' : ['cnt', 'rzd', 'umd', 'vwl'],\n",
        "    'EY' : ['fnt', 'lmd', 'smh', 'unr', 'vwl'],\n",
        "    'F' : ['frc', 'lbd', 'vls'],\n",
        "    'G' : ['stp', 'vcd', 'vel'],\n",
        "    'HH' : ['apr', 'glt'],\n",
        "    'IH' : ['fnt', 'smh', 'unr', 'vwl'],\n",
        "    'IY' : ['fnt', 'hgh', 'unr', 'vwl'],\n",
        "    'JH' : ['alv', 'frc', 'stp', 'vcd'],\n",
        "    'K' : ['stp', 'vel', 'vls'],\n",
        "    'L' : ['alv', 'lat'],\n",
        "    'M' : ['blb', 'nas'],\n",
        "    'N' : ['alv', 'nas'],\n",
        "    'NG' : ['nas', 'vel'],\n",
        "    'OW' : ['bck', 'rnd', 'smh', 'umd', 'vwl'],\n",
        "    'OY' : ['bck', 'fnt', 'lmd', 'rnd', 'smh', 'unr', 'vwl'],\n",
        "    'P' : ['blb', 'stp', 'vls'],\n",
        "    'R' : ['alv', 'apr'],\n",
        "    'S' : ['alv', 'frc', 'vls'],\n",
        "    'SH' : ['frc', 'pla', 'vls'],\n",
        "    'T' : ['alv', 'stp', 'vls'],\n",
        "    'TH' : ['dnt', 'frc', 'vls'],\n",
        "    'UH' : ['bck', 'rnd', 'smh', 'vwl'],\n",
        "    'UW' : ['bck', 'hgh', 'rnd', 'vwl'],\n",
        "    'V' : ['frc', 'lbd', 'vcd'],\n",
        "    'W' : ['apr', 'lbv'],\n",
        "    'Y' : ['apr', 'pal'],\n",
        "    'Z' : ['alv', 'frc', 'vcd'],\n",
        "    'ZH' : ['frc', 'pla', 'vcd']\n",
        "}\n",
        "\n",
        "# Get all symbol combos and create an indexer\n",
        "with open('cmudict-0.7b.symbols') as symfile:\n",
        "  phone_index = {}\n",
        "  index_phone = {}\n",
        "  i = 0\n",
        "  for line in symfile:\n",
        "    phone_index[line.strip()] = i\n",
        "    index_phone[i] = line.strip()\n",
        "    i += 1\n",
        "\n",
        "# Get our word-phoneme dict. First 69 lines are documentation and/or symbol pronunciations.\n",
        "with open('cmudict-0.7b', encoding = 'latin-1') as pronfile:\n",
        "  word_pron = {}\n",
        "  pron_word = {}\n",
        "  for _ in range(69):\n",
        "    next(pronfile)\n",
        "  for line in pronfile:\n",
        "    entry = line.strip().split('  ', 1)\n",
        "    # Add a 'break' token at the beginning and end of the word\n",
        "    word_pron[entry[0]] = ['<beg>'] + entry[1].split() + ['<end>']\n",
        "    pron_word[entry[1]] = entry[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-24 15:30:15--  http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b.symbols\n",
            "Resolving svn.code.sf.net (svn.code.sf.net)... 216.105.38.17\n",
            "Connecting to svn.code.sf.net (svn.code.sf.net)|216.105.38.17|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 281 [text/plain]\n",
            "Saving to: ‘cmudict-0.7b.symbols’\n",
            "\n",
            "\rcmudict-0.7b.symbol   0%[                    ]       0  --.-KB/s               \rcmudict-0.7b.symbol 100%[===================>]     281  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-24 15:30:15 (48.3 MB/s) - ‘cmudict-0.7b.symbols’ saved [281/281]\n",
            "\n",
            "--2020-02-24 15:30:16--  http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b\n",
            "Resolving svn.code.sf.net (svn.code.sf.net)... 216.105.38.17\n",
            "Connecting to svn.code.sf.net (svn.code.sf.net)|216.105.38.17|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3716714 (3.5M) [text/plain]\n",
            "Saving to: ‘cmudict-0.7b’\n",
            "\n",
            "cmudict-0.7b        100%[===================>]   3.54M  4.99MB/s    in 0.7s    \n",
            "\n",
            "2020-02-24 15:30:17 (4.99 MB/s) - ‘cmudict-0.7b’ saved [3716714/3716714]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXWGT4CUVCfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize our individual phonemes\n",
        "attrs = set()\n",
        "for values in phone_defs.values():\n",
        "  attrs.update(values)\n",
        "attrs = sorted(list(attrs))\n",
        "phone_vec = {}\n",
        "i = 0\n",
        "for attr in attrs:\n",
        "  phone_vec[attr] = i\n",
        "  i += 1\n",
        "for phone, attrs in phone_defs.items():\n",
        "  phone_defs[phone] = [0] * 30\n",
        "  for attr in attrs:\n",
        "    phone_defs[phone][phone_vec[attr]] = 1\n",
        "# Include our break tokens, with a separate 'pause' feature\n",
        "phone_defs['<beg>'] = [0] * 29 + [1]\n",
        "phone_defs['<end>'] = [0] * 29 + [1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hVVUx2HgSTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hammingDiff(vec1, vec2):\n",
        "  ''' Simple calc for Hamming distance \n",
        "  between 2 equal length binary vectors.\n",
        "  Can be used for both individual phonemes,\n",
        "  and appended phoneme bigrams/trigrams\n",
        "  (with increasing vectorspace)'''\n",
        "  return sum([1 for i, j in zip(vec1, vec2) if i != j])\n",
        "\n",
        "def closestPhone(vec):\n",
        "  ''' Return a tuple including the closest phoneme to the given vector\n",
        "  based on phoneme attributes, as well as its Hamming distance.'''\n",
        "  d = []\n",
        "  for phone, attr in phone_defs.items():\n",
        "    d.append((phone, hammingDiff(vec, attr)))\n",
        "  return min(d, key = lambda x: x[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLdKfaEzVikP",
        "colab_type": "code",
        "outputId": "e963d89a-23bf-41ac-c559-eb086bc822ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Let's explore the number of possible bigrams and trigrams for phonemes\n",
        "# based on the cmu-dict. This includes syllabic emphasis as different phonemes.\n",
        "bigrams = set()\n",
        "trigrams = set()\n",
        "bigrams_without_syllabic = set()\n",
        "trigrams_without_syllabic = set()\n",
        "syl_emph = '0123'\n",
        "for pron in list(word_pron.values()):\n",
        "  for i in range(len(pron) - 1):\n",
        "    p1 = pron[i]\n",
        "    p2 = pron[i + 1]\n",
        "    if p1[-1] in syl_emph:\n",
        "      p1 = p1[:-1]\n",
        "    if p2[-1] in syl_emph:\n",
        "      p2 = p2[:-1]\n",
        "    bigrams.add((pron[i], pron[i + 1]))\n",
        "    bigrams_without_syllabic.add((p1, p2))\n",
        "    if i < len(pron) - 2:\n",
        "      p3 = pron[i + 2]\n",
        "      if p3[-1] in syl_emph:\n",
        "        p3 = p3[:-1]\n",
        "      trigrams.add((pron[i], pron[i + 1], pron[i + 2]))\n",
        "      trigrams_without_syllabic.add((p1, p2, p3))\n",
        "print(len(bigrams))\n",
        "print(len(bigrams_without_syllabic))\n",
        "print(len(trigrams))\n",
        "print(len(trigrams_without_syllabic))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3024\n",
            "1346\n",
            "38588\n",
            "19559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXzhHmEOlPXt",
        "colab_type": "text"
      },
      "source": [
        "Including syllabic emphasis as separate phonemes, cmu-dict includes 3024 different phoneme bigrams and 38588 different phoneme trigrams.\n",
        "Reduces to 1346 and 19559 if syllabic emphasis is removed.\n",
        "\n",
        "Distance between individual phonemes varies from ~4.3 to ~7.8, with an average of ~5.6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey1K3ZWtiKgF",
        "colab_type": "code",
        "outputId": "85774214-1b88-4d1a-9554-a79c403d55af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from statistics import mean\n",
        "l =[]\n",
        "for p, a in phone_defs.items():\n",
        "  l.append(mean([hammingDiff(a, x) for x in phone_defs.values()]))\n",
        "print(min(l))\n",
        "print(max(l))\n",
        "print(mean(l))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.2682926829268295\n",
            "7.780487804878049\n",
            "5.539559785841761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-lZFW2OjF2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "input_chars = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "num_encoder_tokens = len(input_chars)\n",
        "\n",
        "#### This should be updated to included syllabic emphasis\n",
        "output_chars = sorted(list(phone_defs.keys()))\n",
        "num_decoder_tokens = len(output_chars)\n",
        "\n",
        "max_input_seq_length = max([len(key) for key in word_pron.keys()])\n",
        "max_output_seq_length = max([len(value) for value in word_pron.values()])\n",
        "\n",
        "input_data_length = len(list(word_pron.keys())\n",
        "encoder_input_data = np.zeros(\n",
        "    (input_data_length, max_input_seq_length, num_encoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (input_data_length, max_output_seq_length, num_decoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")\n",
        "\n",
        "decoder_output_data = np.zeros(\n",
        "    (input_data_length, max_output_seq_length, num_decoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")\n",
        "\n",
        "for i, (word, pron) in enumerate(word_pron.items()):\n",
        "  for j, char in enumerate(word):\n",
        "    encoder_input_data[i, ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGCg2lokBiuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set our constants\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "latent_dim = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGEFKaaS0t_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = keras.layers.Input(shape = (None, num_encoder_tokens))\n",
        "encoder = keras.layers.GRU(latent_dim, return_state = True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape = (None, num_decoder_tokens))\n",
        "decoder_gru = keras.layers.GRU(latent_dim, return_sequences = TRUE)\n",
        "decoder_outputs = decoder_gru(decoder_inputs, initial_state = state_h)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation = 'softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH-iLLhe4T9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size = batch_size,\n",
        "          epochs = epochs,\n",
        "          validation_split = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}